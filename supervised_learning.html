<!DOCTYPE html><html><head>
      <title>supervised_learning</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/mmann1123/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.8.13/crossnote/dependencies/katex/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1>Machine Learning - Supervised Examples</h1>
<h2 id="country-cuisine-classifier">Country Cuisine Classifier </h2>
<p>As in the last example we will use the following variables:</p>
<ul>
<li>Country</li>
<li>Region</li>
<li>Staple Food</li>
<li>Preferred Cuisine</li>
<li>Climate</li>
</ul>
<p>However this time we will use supervised classfication methods to classify the data.</p>
<p>Copy and paste the following in the QGIS Python console to create the dataset called <code>data</code>:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np
<span class="token keyword keyword-import">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword keyword-as">as</span> plt
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword keyword-import">import</span> DecisionTreeClassifier
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword keyword-import">import</span> KMeans<span class="token punctuation">,</span>MeanShift
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword keyword-import">import</span> RandomForestClassifier
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword keyword-import">import</span> GaussianNB
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword keyword-import">import</span> LogisticRegression
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword keyword-import">import</span> LabelEncoder
<span class="token keyword keyword-import">import</span> pandas <span class="token keyword keyword-as">as</span> pd

<span class="token comment"># Sample data with regional variations</span>
data <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"Country"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token string">"Japan"</span><span class="token punctuation">,</span>
        <span class="token string">"Japan"</span><span class="token punctuation">,</span>
        <span class="token string">"Japan"</span><span class="token punctuation">,</span>
        <span class="token string">"Mexico"</span><span class="token punctuation">,</span>
        <span class="token string">"Mexico"</span><span class="token punctuation">,</span>
        <span class="token string">"Mexico"</span><span class="token punctuation">,</span>
        <span class="token string">"India"</span><span class="token punctuation">,</span>
        <span class="token string">"India"</span><span class="token punctuation">,</span>
        <span class="token string">"India"</span><span class="token punctuation">,</span>
        <span class="token string">"USA"</span><span class="token punctuation">,</span>
        <span class="token string">"USA"</span><span class="token punctuation">,</span>
        <span class="token string">"USA"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"Region"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token string">"North Japan"</span><span class="token punctuation">,</span>
        <span class="token string">"South Japan"</span><span class="token punctuation">,</span>
        <span class="token string">"Central Japan"</span><span class="token punctuation">,</span>
        <span class="token string">"North Mexico"</span><span class="token punctuation">,</span>
        <span class="token string">"South Mexico"</span><span class="token punctuation">,</span>
        <span class="token string">"Central Mexico"</span><span class="token punctuation">,</span>
        <span class="token string">"North India"</span><span class="token punctuation">,</span>
        <span class="token string">"South India"</span><span class="token punctuation">,</span>
        <span class="token string">"Central India"</span><span class="token punctuation">,</span>
        <span class="token string">"North USA"</span><span class="token punctuation">,</span>
        <span class="token string">"South USA"</span><span class="token punctuation">,</span>
        <span class="token string">"Central USA"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"Staple Food"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token string">"Rice"</span><span class="token punctuation">,</span>
        <span class="token string">"Rice"</span><span class="token punctuation">,</span>
        <span class="token string">"Rice"</span><span class="token punctuation">,</span>
        <span class="token string">"Corn"</span><span class="token punctuation">,</span>
        <span class="token string">"Corn"</span><span class="token punctuation">,</span>
        <span class="token string">"Corn"</span><span class="token punctuation">,</span>
        <span class="token string">"Wheat"</span><span class="token punctuation">,</span>
        <span class="token string">"Wheat"</span><span class="token punctuation">,</span>
        <span class="token string">"Rice"</span><span class="token punctuation">,</span>  <span class="token comment"># regional variation within India</span>
        <span class="token string">"Wheat"</span><span class="token punctuation">,</span>
        <span class="token string">"Corn"</span><span class="token punctuation">,</span>
        <span class="token string">"Wheat"</span><span class="token punctuation">,</span>  <span class="token comment"># regional variation within USA</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"Preferred Cuisine"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token string">"Sushi"</span><span class="token punctuation">,</span>
        <span class="token string">"Ramen"</span><span class="token punctuation">,</span>
        <span class="token string">"Tempura"</span><span class="token punctuation">,</span>
        <span class="token string">"Tacos"</span><span class="token punctuation">,</span>
        <span class="token string">"Enchiladas"</span><span class="token punctuation">,</span>
        <span class="token string">"Tamales"</span><span class="token punctuation">,</span>
        <span class="token string">"Curry"</span><span class="token punctuation">,</span>
        <span class="token string">"Dosa"</span><span class="token punctuation">,</span>
        <span class="token string">"Biryani"</span><span class="token punctuation">,</span>
        <span class="token string">"Burgers"</span><span class="token punctuation">,</span>
        <span class="token string">"BBQ"</span><span class="token punctuation">,</span>
        <span class="token string">"Pizza"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"Climate"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token string">"Temperate"</span><span class="token punctuation">,</span>
        <span class="token string">"Subtropical"</span><span class="token punctuation">,</span>
        <span class="token string">"Temperate"</span><span class="token punctuation">,</span>
        <span class="token string">"Tropical"</span><span class="token punctuation">,</span>
        <span class="token string">"Tropical"</span><span class="token punctuation">,</span>
        <span class="token string">"Arid"</span><span class="token punctuation">,</span>
        <span class="token string">"Tropical"</span><span class="token punctuation">,</span>
        <span class="token string">"Subtropical"</span><span class="token punctuation">,</span>
        <span class="token string">"Tropical"</span><span class="token punctuation">,</span>
        <span class="token string">"Temperate"</span><span class="token punctuation">,</span>
        <span class="token string">"Arid"</span><span class="token punctuation">,</span>
        <span class="token string">"Temperate"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><p>Example data:</p>
<table>
<thead>
<tr>
<th>--</th>
<th>Country</th>
<th>Region</th>
<th>Staple Food</th>
<th>Preferred Cuisine</th>
<th>Climate</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Japan</td>
<td>North Japan</td>
<td>Rice</td>
<td>Sushi</td>
<td>Temperate</td>
</tr>
<tr>
<td>1</td>
<td>Japan</td>
<td>South Japan</td>
<td>Rice</td>
<td>Ramen</td>
<td>Subtropical</td>
</tr>
<tr>
<td>2</td>
<td>Japan</td>
<td>Central Japan</td>
<td>Rice</td>
<td>Tempura</td>
<td>Temperate</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
<p>Here we are defining a function that can visualize our classification model in a 2D space. This function will take the data, the <code>x</code> and <code>x2</code> columns to use as features, and the target variable. It will encode the categorical data, fit the model, and plot the results.</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">visualize_classifier</span><span class="token punctuation">(</span>
    data<span class="token punctuation">,</span>
    classifier<span class="token operator">=</span><span class="token string">"DecisionTreeClassifier"</span><span class="token punctuation">,</span>
    cmap<span class="token operator">=</span><span class="token string">"rainbow"</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token string">"Country"</span><span class="token punctuation">,</span>
    x<span class="token operator">=</span><span class="token string">"Staple Food"</span><span class="token punctuation">,</span>
    x2<span class="token operator">=</span><span class="token string">"Climate"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># create a dictionary to map the classifier to the model</span>
    classifier_dict <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"KMeans"</span><span class="token punctuation">:</span> KMeans<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"MeanShift"</span><span class="token punctuation">:</span> MeanShift<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"RandomForestClassifier"</span><span class="token punctuation">:</span> RandomForestClassifier<span class="token punctuation">(</span>
            random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> n_estimators<span class="token operator">=</span><span class="token number">100</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"DecisionTreeClassifier"</span><span class="token punctuation">:</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"GaussianNB"</span><span class="token punctuation">:</span> GaussianNB<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"LogisticRegression"</span><span class="token punctuation">:</span> LogisticRegression<span class="token punctuation">(</span>
            multi_class<span class="token operator">=</span><span class="token string">"multinomial"</span><span class="token punctuation">,</span> solver<span class="token operator">=</span><span class="token string">"lbfgs"</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>

    <span class="token comment"># Check if classifier is valid</span>
    <span class="token keyword keyword-if">if</span> classifier <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> classifier_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-raise">raise</span> ValueError<span class="token punctuation">(</span>
            <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>classifier<span class="token punctuation">}</span></span><span class="token string"> is not a valid classifier, please choose one of </span><span class="token interpolation"><span class="token punctuation">{</span>classifier_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
        <span class="token punctuation">)</span>

    <span class="token comment"># throw error if x and x2 are not columns in data</span>
    <span class="token keyword keyword-if">if</span> x <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> data<span class="token punctuation">.</span>columns<span class="token punctuation">:</span>
        <span class="token keyword keyword-raise">raise</span> ValueError<span class="token punctuation">(</span>
            <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>x<span class="token punctuation">}</span></span><span class="token string"> is not a column in the data, please choose one of </span><span class="token interpolation"><span class="token punctuation">{</span>data<span class="token punctuation">.</span>columns<span class="token punctuation">}</span></span><span class="token string">"</span></span>
        <span class="token punctuation">)</span>

    <span class="token comment"># Encode the categorical data</span>
    le_x <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    le_x2 <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    le_y <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>

    X <span class="token operator">=</span> le_x<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span>
    X2 <span class="token operator">=</span> le_x2<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span>x2<span class="token punctuation">]</span><span class="token punctuation">)</span>
    y <span class="token operator">=</span> le_y<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># Combine features</span>
    X <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>X<span class="token punctuation">,</span> X2<span class="token punctuation">]</span>

    <span class="token comment"># Create and fit the model</span>
    model <span class="token operator">=</span> classifier_dict<span class="token punctuation">[</span>classifier<span class="token punctuation">]</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

    <span class="token comment"># Add jitter to avoid overlapping</span>
    jitter_strength <span class="token operator">=</span> <span class="token number">0.2</span>
    X_jittered <span class="token operator">=</span> X <span class="token operator">+</span> jitter_strength <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token comment"># Plot the training points</span>
    scatter <span class="token operator">=</span> ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>
        X_jittered<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        X_jittered<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        c<span class="token operator">=</span>y<span class="token punctuation">,</span>
        s<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>
        cmap<span class="token operator">=</span>cmap<span class="token punctuation">,</span>
        clim<span class="token operator">=</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        zorder<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> txt <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>le_y<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax<span class="token punctuation">.</span>annotate<span class="token punctuation">(</span>txt<span class="token punctuation">,</span> <span class="token punctuation">(</span>X_jittered<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_jittered<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">"right"</span><span class="token punctuation">)</span>

    ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"tight"</span><span class="token punctuation">)</span>
    xlim <span class="token operator">=</span> ax<span class="token punctuation">.</span>get_xlim<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ylim <span class="token operator">=</span> ax<span class="token punctuation">.</span>get_ylim<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Fit the estimator</span>
    xx<span class="token punctuation">,</span> yy <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">*</span>xlim<span class="token punctuation">,</span> num<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">*</span>ylim<span class="token punctuation">,</span> num<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    Z <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token comment"># Create a color plot with the results</span>
    n_classes <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
    contours <span class="token operator">=</span> ax<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>
        xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> levels<span class="token operator">=</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>n_classes <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">,</span> zorder<span class="token operator">=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># Label the contour lines</span>
    contour_lines <span class="token operator">=</span> ax<span class="token punctuation">.</span>contour<span class="token punctuation">(</span>xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> colors<span class="token operator">=</span><span class="token string">"k"</span><span class="token punctuation">,</span> linewidths<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>

    <span class="token comment"># Add x and y axis labels</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>

    <span class="token comment"># print accuracy</span>
    <span class="token keyword keyword-try">try</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword keyword-except">except</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-pass">pass</span>

    ax<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span>xlim<span class="token operator">=</span>xlim<span class="token punctuation">,</span> ylim<span class="token operator">=</span>ylim<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p>We will use the <code>Staple Food</code> and <code>Climate</code> columns as features and the <code>Country</code> column as the target variable. We will use a decision tree classifier to fit the model and plot the results.</p>
<p>There are 4 supervised classifiers available:</p>
<ul>
<li>'RandomForestClassifier'</li>
<li>'GaussianNB'</li>
<li>'LogisticRegression'</li>
<li>'DecisionTreeClassifier'</li>
</ul>
<p>Try using different supervised classifiers to see how they perform with the given data.</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>visualize_classifier<span class="token punctuation">(</span>
    data<span class="token punctuation">,</span> 
    classifier<span class="token operator">=</span><span class="token string">"RandomForestClassifier"</span><span class="token punctuation">,</span> 
    x<span class="token operator">=</span><span class="token string">"Preferred Cuisine"</span><span class="token punctuation">,</span> 
    x2<span class="token operator">=</span><span class="token string">"Climate"</span>
<span class="token punctuation">)</span>
</code></pre><blockquote>
<p>Try using different classifiers and features to see how they perform with the given data.</p>
</blockquote>
<h2 id="wine-data-classifier">Wine Data Classifier </h2>
<p>In this section, we will use the wine dataset from scikit-learn to find the ideal classifier and best two features for classification. The wine dataset is a classic dataset for classification and contains chemical analysis of wines grown in the same region in Italy.</p>
<p>First, we need to load the wine dataset:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword keyword-import">import</span> load_wine
<span class="token keyword keyword-import">import</span> pandas <span class="token keyword keyword-as">as</span> pd

<span class="token comment"># Load Wine dataset</span>
wine <span class="token operator">=</span> load_wine<span class="token punctuation">(</span><span class="token punctuation">)</span>
wine_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> columns<span class="token operator">=</span>wine<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
wine_data<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span> <span class="token operator">=</span> wine<span class="token punctuation">.</span>target
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>wine_data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><p>The dataset contains 13 features:</p>
<ul>
<li>alcohol</li>
<li>malic_acid</li>
<li>ash</li>
<li>alcalinity_of_ash</li>
<li>magnesium</li>
<li>total_phenols</li>
<li>flavanoids</li>
<li>nonflavanoid_phenols</li>
<li>proanthocyanins</li>
<li>color_intensity</li>
<li>hue</li>
<li>od280/od315_of_diluted_wines</li>
<li>proline</li>
</ul>
<p>Now let's use the <code>alcohol</code> and <code>malic_acid</code> columns as features and the <code>y</code> column as the target variable. We will use different classifiers to see which one performs best.</p>
<p>First, let's try using the <code>DecisionTreeClassifier</code>:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Visualize the classifier with DecisionTreeClassifier</span>
visualize_classifier<span class="token punctuation">(</span>
    wine_data<span class="token punctuation">,</span>
    classifier<span class="token operator">=</span><span class="token string">"DecisionTreeClassifier"</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token string">"target"</span><span class="token punctuation">,</span>
    x<span class="token operator">=</span><span class="token string">"alcohol"</span><span class="token punctuation">,</span>
    x2<span class="token operator">=</span><span class="token string">"malic_acid"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><p>Next, let's try using the <code>LogisticRegression</code> :</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Visualize the classifier with LogisticRegression</span>
visualize_classifier<span class="token punctuation">(</span>
    wine_data<span class="token punctuation">,</span>
    classifier<span class="token operator">=</span><span class="token string">"LogisticRegression"</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token string">"target"</span><span class="token punctuation">,</span>
    x<span class="token operator">=</span><span class="token string">"alcohol"</span><span class="token punctuation">,</span>
    x2<span class="token operator">=</span><span class="token string">"malic_acid"</span>
<span class="token punctuation">)</span>
</code></pre><p>and so on...</p>
<p>You can try other combinations of features and classifiers to find the best model and features for the wine dataset. For example, you can use <code>color_intensity</code> and <code>hue</code> as features and the <code>GaussianNB</code> classifier:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Visualize the classifier with GaussianNB and different features</span>
visualize_classifier<span class="token punctuation">(</span>
    wine_data<span class="token punctuation">,</span>
    classifier<span class="token operator">=</span><span class="token string">"GaussianNB"</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token string">"target"</span><span class="token punctuation">,</span>
    x<span class="token operator">=</span><span class="token string">"color_intensity"</span><span class="token punctuation">,</span>
    x2<span class="token operator">=</span><span class="token string">"hue"</span>
<span class="token punctuation">)</span>
</code></pre><p>This tutorial allows students to explore different classifiers and feature combinations to find the best model for classifying the wine dataset.</p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>